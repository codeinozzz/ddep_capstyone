{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div\n",
    "  style=\"\n",
    "    background-color: #f0f0f0;\n",
    "    color:rgb(56, 56, 56);\n",
    "    padding: 8px;\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    gap: 100px;\n",
    "  \"\n",
    ">\n",
    "  <img src=\"./images/brand.svg\" style=\"max-height: 80px;\">\n",
    "  <strong>\n",
    "    AI Saga: Deep Learning & Generative AI</br>\n",
    "    2.Lab GAN Explorer: CNNs as Discriminators and Bias Detection</br>\n",
    "  </strong>\n",
    "  <emph>\n",
    "    Student Name: [Complete with your name]</br>\n",
    "    Date: [Fill up with the submission date]</br>\n",
    "  </emph>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This lab explores how CNNs function as \"critics\" in generative AI systems. You'll work with a Generative Adversarial Network (GAN), modify its CNN-based discriminator, and analyze the model for biases. This hands-on experience demonstrates the dual nature of CNNs: not just as classifiers, but as quality evaluators guiding generation.\n",
    "\n",
    "---\n",
    "\n",
    "## Description\n",
    "\n",
    "This lab is structured around two parts.\n",
    "\n",
    "### Part 1: Understanding the GAN Discriminator\n",
    "\n",
    "You will:\n",
    "- Load Fashion-MNIST dataset and set up data pipelines\n",
    "- Review a provided generator architecture\n",
    "- **Implement** a CNN discriminator from scratch\n",
    "- **Complete** the adversarial training loop\n",
    "- **Visualize** training dynamics (loss curves, generated samples, discriminator confidence)\n",
    "- **Experiment** by modifying the discriminator architecture and observing impact\n",
    "\n",
    "**Key Deliverables:**\n",
    "- Working discriminator implementation\n",
    "- Complete GAN training loop\n",
    "- Visualizations of training progress\n",
    "- Before/after comparison of architecture modification\n",
    "- Answers to 2 reflection questions\n",
    "\n",
    "### Part 2: Bias Detection and Critical Analysis\n",
    "\n",
    "You will:\n",
    "- Analyze Fashion-MNIST class distribution\n",
    "- Train a simple classifier to label generated images\n",
    "- **Identify** which clothing categories are over/under-represented in generated samples\n",
    "- **Document** 2-3 specific bias examples with evidence (e.g., class imbalance, quality variance, mode collapse)\n",
    "- **Propose and test** one mitigation strategy (e.g., weighted sampling, conditional generation, architecture changes)\n",
    "- **Reflect** on ethical implications of deploying biased generative models\n",
    "\n",
    "**Key Deliverables:**\n",
    "- Class distribution analysis (real vs. generated)\n",
    "- 2-3 documented bias examples with:\n",
    "  - Clear description\n",
    "  - Quantitative evidence\n",
    "  - Potential source analysis\n",
    "  - Impact assessment\n",
    "- One tested mitigation strategy with results\n",
    "- Ethical reflection (3-4 sentences)\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Work through sections sequentially** - Part 1 must be completed before Part 2\n",
    "2. **Complete all code cells marked with `# TODO`** - These are required for full credit\n",
    "3. **Answer all reflection questions** - Use the designated markdown cells\n",
    "4. **Document your findings** - Use clear visualizations and written analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ IMPORTANT NOTICE FOR STUDENTS ⚠️\n",
    "#\n",
    "# Please make sure to check the official instructions for this assignment in Canvas LMS\n",
    "# as they may have been updated or changed. The instructions above are provided for\n",
    "# reference only and may not reflect the most current requirements.\n",
    "#\n",
    "# Always refer to Canvas LMS for:\n",
    "# - Latest assignment requirements\n",
    "# - Due dates\n",
    "# - Grading criteria\n",
    "# - Any special instructions\n",
    "#\n",
    "# When in doubt, ask your instructor for clarification.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the GAN Discriminator\n",
    "\n",
    "### 1.1 Load Fashion-MNIST Dataset\n",
    "\n",
    "Fashion-MNIST contains 70,000 grayscale images (28x28) across 10 clothing categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define data transformations\n",
    "# Hint: Use transforms.ToTensor() and normalize to [-1, 1] range. Why we need to do this?\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        # Your code here\n",
    "    ]\n",
    ")\n",
    "\n",
    "# TODO: Load Fashion-MNIST dataset\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    # Your code here\n",
    ")\n",
    "\n",
    "# TODO: Create DataLoader with batch_size=128\n",
    "train_loader = DataLoader(\n",
    "    # Your code here\n",
    ")\n",
    "\n",
    "\n",
    "# TODO: Fashion-MNIST class names\n",
    "class_names = [\n",
    "    # Your code here\n",
    "]\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define the Generator Network\n",
    "\n",
    "The generator takes random noise (latent vector) and transforms it into a 28x28 image.\n",
    "\n",
    "**This is provided for you - review the architecture carefully!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 256, 7, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "# Test generator\n",
    "generator = Generator(latent_dim=100).to(device)\n",
    "test_noise = torch.randn(4, 100).to(device)\n",
    "test_output = generator(test_noise)\n",
    "print(f\"Generator output shape: {test_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define the CNN Discriminator Network\n",
    "\n",
    "Complete the discriminator implementation.\n",
    "\n",
    "The discriminator is a CNN that learns to distinguish between real and generated images.\n",
    "\n",
    "#### Key Requirements:\n",
    "- Input: 28x28 grayscale image (1 channel)\n",
    "- Use Conv2d layers with stride=2 for downsampling\n",
    "- Use LeakyReLU activation (negative_slope=0.2)\n",
    "- Output: Single probability value (Sigmoid activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_layers=3, base_channels=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # TODO: Build the discriminator architecture\n",
    "        # Layer 1: 1 -> base_channels (28x28 -> 14x14)\n",
    "        # Layer 2: base_channels -> base_channels*2 (14x14 -> 7x7)\n",
    "        # Layer 3: base_channels*2 -> base_channels*4 (7x7 -> 3x3)\n",
    "        # Final: base_channels*4 -> 1 (3x3 -> 1x1)\n",
    "\n",
    "        # Hint: Use nn.Sequential to build the model\n",
    "        self.model = nn.Sequential(\n",
    "            # Your code here\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        # TODO: Pass image through model and return single probability\n",
    "        # Hint: Use .view() or .squeeze() to get correct output shape\n",
    "        pass\n",
    "\n",
    "\n",
    "# Test discriminator\n",
    "discriminator = Discriminator(num_layers=3, base_channels=64).to(device)\n",
    "test_input = torch.randn(4, 1, 28, 28).to(device)\n",
    "test_output = discriminator(test_input)\n",
    "print(f\"Discriminator output shape: {test_output.shape}\")  # Should be [4]\n",
    "print(f\"Sample outputs: {test_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REFLECTION QUESTION 1:\n",
    "\n",
    "Compare this discriminator to a typical CNN classifier (e.g., for MNIST digit recognition):\n",
    "- What's different about the final layer?\n",
    "- Why do we use Sigmoid activation at the end instead of Softmax?\n",
    "- What does the output represent?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "_(Write your response here - 3-5 sentences)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "num_epochs = 10\n",
    "\n",
    "# TODO: Initialize models\n",
    "generator = # Your code here\n",
    "discriminator = # Your code here\n",
    "\n",
    "# TODO: Define loss function (Binary Cross Entropy)\n",
    "criterion = # Your code here\n",
    "\n",
    "# TODO: Define optimizers (Adam with lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_G = # Your code here\n",
    "optimizer_D = # Your code here\n",
    "\n",
    "print(\"Training setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 GAN Training Loop\n",
    "\n",
    "Complete the adversarial training loop.\n",
    "\n",
    "**Adversarial Training Process:**\n",
    "1. **Train Discriminator**: Learn to distinguish real from fake\n",
    "2. **Train Generator**: Learn to fool the discriminator\n",
    "3. Repeat until equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for tracking\n",
    "history = {\n",
    "    'd_loss': [],\n",
    "    'g_loss': [],\n",
    "    'd_real_acc': [],\n",
    "    'd_fake_acc': [],\n",
    "    'generated_samples': []\n",
    "}\n",
    "\n",
    "# Fixed noise for visualization\n",
    "fixed_noise = torch.randn(64, latent_dim).to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_d_loss = 0\n",
    "    epoch_g_loss = 0\n",
    "    epoch_d_real_acc = 0\n",
    "    epoch_d_fake_acc = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    for i, (real_imgs, _) in enumerate(pbar):\n",
    "        batch_size = real_imgs.size(0)\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        \n",
    "        # TODO: Create labels (real=1, fake=0)\n",
    "        real_labels = # Your code here\n",
    "        fake_labels = # Your code here\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        # TODO: Zero gradients\n",
    "        \n",
    "        # TODO: Get discriminator output on real images\n",
    "        real_output = # Your code here\n",
    "        \n",
    "        # TODO: Calculate loss on real images\n",
    "        d_loss_real = # Your code here\n",
    "        \n",
    "        # TODO: Generate fake images\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_imgs = # Your code here (use generator)\n",
    "        \n",
    "        # TODO: Get discriminator output on fake images\n",
    "        fake_output = # Your code here (use .detach() on fake_imgs!)\n",
    "        \n",
    "        # TODO: Calculate loss on fake images\n",
    "        d_loss_fake = # Your code here\n",
    "        \n",
    "        # TODO: Total discriminator loss\n",
    "        d_loss = # Your code here\n",
    "        \n",
    "        # TODO: Backpropagate and update discriminator\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        # TODO: Zero gradients\n",
    "        \n",
    "        # TODO: Generate new fake images\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_imgs = # Your code here\n",
    "        \n",
    "        # TODO: Get discriminator output\n",
    "        fake_output = # Your code here\n",
    "        \n",
    "        # TODO: Generator loss (wants discriminator to think fakes are real!)\n",
    "        g_loss = # Your code here (hint: use real_labels)\n",
    "        \n",
    "        # TODO: Backpropagate and update generator\n",
    "        \n",
    "        # Track metrics\n",
    "        epoch_d_loss += d_loss.item()\n",
    "        epoch_g_loss += g_loss.item()\n",
    "        epoch_d_real_acc += (real_output > 0.5).float().mean().item()\n",
    "        epoch_d_fake_acc += (fake_output < 0.5).float().mean().item()\n",
    "    \n",
    "    # Store epoch metrics\n",
    "    num_batches = len(train_loader)\n",
    "    history['d_loss'].append(epoch_d_loss / num_batches)\n",
    "    history['g_loss'].append(epoch_g_loss / num_batches)\n",
    "    history['d_real_acc'].append(epoch_d_real_acc / num_batches)\n",
    "    history['d_fake_acc'].append(epoch_d_fake_acc / num_batches)\n",
    "    \n",
    "    # Generate samples for visualization\n",
    "    with torch.no_grad():\n",
    "        samples = generator(fixed_noise).cpu()\n",
    "        history['generated_samples'].append(samples)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: D_loss={history['d_loss'][-1]:.4f}, G_loss={history['g_loss'][-1]:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create two subplots showing:\n",
    "# 1. Discriminator and Generator loss over epochs\n",
    "# 2. Discriminator accuracy on real vs. fake images\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Your visualization code here\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REFLECTION QUESTION 2:\n",
    "\n",
    "Looking at the loss curves:\n",
    "- What would it mean if the discriminator loss goes to zero?\n",
    "- What would it mean if the generator loss goes to zero?\n",
    "- Why is it important that both losses stay relatively balanced?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "_(Write your response here - 5-7 sentences)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Visualize Generated Samples at Different Training Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generated_images(samples, epoch, n_images=16):\n",
    "    \"\"\"Display a grid of generated images.\"\"\"\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "    fig.suptitle(f\"Generated Samples - Epoch {epoch}\", fontsize=14)\n",
    "\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        img = samples[idx].squeeze().numpy()\n",
    "        img = (img + 1) / 2  # Denormalize\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# TODO: Show samples at beginning, middle, and end of training\n",
    "checkpoints = [0, num_epochs // 2, num_epochs - 1]\n",
    "for checkpoint in checkpoints:\n",
    "    show_generated_images(history[\"generated_samples\"][checkpoint], checkpoint + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Discriminator Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate discriminator on 1000 real and 1000 fake samples\n",
    "# Create a histogram showing the distribution of discriminator scores\n",
    "\n",
    "discriminator.eval()\n",
    "real_scores = []\n",
    "fake_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# TODO: Plot histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Your plotting code here\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average discriminator score for REAL images: {np.mean(real_scores):.3f}\")\n",
    "print(f\"Average discriminator score for FAKE images: {np.mean(fake_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 EXPERIMENT: Modify the Discriminator Architecture\n",
    "\n",
    "Modify the discriminator and observe the impact.\n",
    "\n",
    "Try ONE of these modifications:\n",
    "- Change `num_layers` (2 or 4 instead of 3)\n",
    "- Change `base_channels` (32 or 128 instead of 64)\n",
    "- Add dropout layers\n",
    "\n",
    "Train for 5 epochs and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create modified discriminator and retrain\n",
    "print(\"EXPERIMENT: Modified Discriminator\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Your experimental code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENT Findings:\n",
    "\n",
    "**Modification Tested:** _(describe what you changed)_\n",
    "\n",
    "**Observed Impact:**\n",
    "\n",
    "_(Write 5-7 sentences describing what happened when you modified the discriminator. Compare generation quality, training stability, and loss curves to the original model.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Bias Detection and Critical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dataset Analysis: Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Count samples per class in Fashion-MNIST\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# TODO: Create a bar chart showing class distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Your plotting code here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generation Quality Analysis by Class\n",
    "\n",
    "We'll train a simple classifier to label generated images, then analyze which classes are generated most/least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple classifier (provided)\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), nn.Linear(64 * 7 * 7, 128), nn.ReLU(), nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "# TODO: Train the classifier for 3 epochs\n",
    "print(\"Training classifier...\")\n",
    "classifier = SimpleClassifier().to(device)\n",
    "\n",
    "# Your training code here\n",
    "\n",
    "print(\"Classifier training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate 5000 samples and classify them\n",
    "classifier.eval()\n",
    "generator.eval()\n",
    "\n",
    "generated_class_counts = defaultdict(int)\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# TODO: Create side-by-side bar charts comparing real vs. generated distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# Your plotting code here\n",
    "plt.show()\n",
    "\n",
    "# Print comparison table\n",
    "print(\"\\nGeneration Distribution Analysis:\")\n",
    "print(f\"{'Class':<15} {'Real %':>10} {'Generated %':>15} {'Difference':>15}\")\n",
    "print(\"-\" * 60)\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Identify Failure Modes and Bias Examples\n",
    "\n",
    "Find and visualize 2-3 specific examples of bias or quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate samples, score them with the discriminator,\n",
    "# and collect low-quality examples (discriminator score < 0.3)\n",
    "\n",
    "failure_examples = defaultdict(list)\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# TODO: Visualize failure examples for classes with poor generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Bias Documentation\n",
    "\n",
    "Document 2-3 specific bias examples with evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIAS EXAMPLE 1:\n",
    "\n",
    "**Description:**\n",
    "\n",
    "_(Describe the bias you observed - e.g., class imbalance, quality variance, etc.)_\n",
    "\n",
    "**Evidence:**\n",
    "\n",
    "_(Provide specific numbers, percentages, or observations from your analysis)_\n",
    "\n",
    "**Potential Source:**\n",
    "\n",
    "_(What might be causing this bias? Consider dataset, architecture, or training dynamics)_\n",
    "\n",
    "**Impact:**\n",
    "\n",
    "_(If deployed in a real application, how would this bias affect users or outcomes?)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIAS EXAMPLE 2:\n",
    "\n",
    "**Description:**\n",
    "\n",
    "_(Your analysis here)_\n",
    "\n",
    "**Evidence:**\n",
    "\n",
    "_(Your data here)_\n",
    "\n",
    "**Potential Source:**\n",
    "\n",
    "_(Your explanation here)_\n",
    "\n",
    "**Impact:**\n",
    "\n",
    "_(Your assessment here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIAS EXAMPLE 3 (Optional):\n",
    "\n",
    "**Description:**\n",
    "\n",
    "**Evidence:**\n",
    "\n",
    "**Potential Source:**\n",
    "\n",
    "**Impact:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Proposed Mitigation Strategy\n",
    "\n",
    "Choose ONE mitigation approach and test it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MITIGATION STRATEGY:\n",
    "\n",
    "**Approach:**\n",
    "\n",
    "_(Describe what mitigation strategy you chose - e.g., weighted sampling, conditional GAN, architecture changes, etc.)_\n",
    "\n",
    "**Implementation:**\n",
    "\n",
    "_(Explain how you implemented this mitigation)_\n",
    "\n",
    "**Expected Impact:**\n",
    "\n",
    "_(What improvements do you expect this to bring?)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your chosen mitigation strategy\n",
    "print(\"MITIGATION TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MITIGATION RESULTS:\n",
    "\n",
    "**Effectiveness:**\n",
    "\n",
    "_(Did your mitigation work? What improved? What didn't?)_\n",
    "\n",
    "**Trade-offs:**\n",
    "\n",
    "_(What are the pros and cons of this approach? Any new problems introduced?)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Ethical Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETHICAL REFLECTION (3-4 sentences):\n",
    "\n",
    "**What are the ethical implications of deploying a generative model with the biases you identified?**\n",
    "\n",
    "_(Consider: Who might be harmed? How could biases be amplified? What responsibilities do developers have?)_\n",
    "\n",
    "**Your reflection:**\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
